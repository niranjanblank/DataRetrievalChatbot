{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:18:47.733467700Z",
     "start_time": "2023-12-22T11:18:47.717466600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:18:48.188771400Z",
     "start_time": "2023-12-22T11:18:48.173770800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "OPENAI_API_KEY=os.getenv('OPENAI_API_KEY')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:18:48.550944400Z",
     "start_time": "2023-12-22T11:18:48.543940700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:18:48.929438400Z",
     "start_time": "2023-12-22T11:18:48.910371600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 4500.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# loader\n",
    "# use the data from documents to create vector store\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "loader = DirectoryLoader('./data', glob=\"**/*.txt\", loader_cls=TextLoader, show_progress=True)\n",
    "\n",
    "data = loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:18:50.092270400Z",
     "start_time": "2023-12-22T11:18:49.552740100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:18:50.358441700Z",
     "start_time": "2023-12-22T11:18:50.344440100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# chunking the data to store in the database\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:18:51.329419Z",
     "start_time": "2023-12-22T11:18:51.322421300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:18:52.065417800Z",
     "start_time": "2023-12-22T11:18:52.048404900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niran\\anaconda3\\envs\\pytorch_learning\\lib\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "# embeddings from huggingface\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "embeddings = HuggingFaceInstructEmbeddings(model_name='hkunlp/instructor-large')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:18:56.501695300Z",
     "start_time": "2023-12-22T11:18:52.431214500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# embeddings from openai\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "# embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T09:51:34.631890800Z",
     "start_time": "2023-12-22T09:51:34.270075700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# loading vectors into VectorDB\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "vectorstore.save_local(\"vectorstore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:19:01.036806900Z",
     "start_time": "2023-12-22T11:19:00.335567300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# load the vectorstore\n",
    "vectorstore = FAISS.load_local(\"vectorstore\", embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:19:04.152947600Z",
     "start_time": "2023-12-22T11:19:04.144949100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T09:58:43.335791500Z",
     "start_time": "2023-12-22T09:58:43.331792Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Prompt to answer question\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"You are a helpful assistant for our restaurant that answers the queries of the customer\n",
    "\n",
    "{context}\n",
    "Question: {question}\n",
    "Answer here: \"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template = prompt_template, input_variables=[\"context\",\"question\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:19:11.634076200Z",
     "start_time": "2023-12-22T11:19:11.600714900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# memory to store chat history\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, output_key=\"answer\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:19:15.721295400Z",
     "start_time": "2023-12-22T11:19:15.082392400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niran\\anaconda3\\envs\\pytorch_learning\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI, HuggingFaceHub\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "chain_type = {\"prompt\": PROMPT}\n",
    "# to use open ai, uncomment it\n",
    "# llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# to use models from huggingface, uncomment this\n",
    "llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":0.5, \"max_length\":512})\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    memory=memory,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    combine_docs_chain_kwargs=chain_type\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:19:19.002806Z",
     "start_time": "2023-12-22T11:19:18.463819900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "query=\"What are your pricing\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:22:51.702019900Z",
     "start_time": "2023-12-22T11:22:51.693019600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "{'question': 'What are your pricing',\n 'chat_history': [HumanMessage(content='How do I complain about the staff?'),\n  AIMessage(content='If you are unhappy with your dining experience, please inform the waiter or hostess immediately. If you feel the waiter or hostess has not met your expectations, you can also contact the manager.'),\n  HumanMessage(content='What are you open?'),\n  AIMessage(content='We are open from 11:00 AM to 10:00 PM from Monday to Saturday and from 11:00 AM to 9:00 PM on Sundays.'),\n  HumanMessage(content='What are you located?'),\n  AIMessage(content='We are located at 123 Main Street, Downtown City. Our restaurant is easily accessible from major roads and public transport.'),\n  HumanMessage(content='Summarize the questions I have asked till now'),\n  AIMessage(content='If you are unhappy with your dining experience, please inform the waiter or hostess immediately. If you feel the waiter or hostess has not met your expectations, you can also contact the manager.'),\n  HumanMessage(content='What do you recommend me to order?'),\n  AIMessage(content='I recommend the Grilled Salmon and Tiramisu.'),\n  HumanMessage(content='What are your pricing'),\n  AIMessage(content='Our appetizers are $7-$9, main courses are $16-$26, desserts are $7-$9, and beverages start at $2.')],\n 'answer': 'Our appetizers are $7-$9, main courses are $16-$26, desserts are $7-$9, and beverages start at $2.'}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain({\"question\": query})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:22:54.600749200Z",
     "start_time": "2023-12-22T11:22:52.232756100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
