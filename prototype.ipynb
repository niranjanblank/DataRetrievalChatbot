{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:49:03.091904400Z",
     "start_time": "2023-12-22T11:49:03.078904200Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:49:03.106903200Z",
     "start_time": "2023-12-22T11:49:03.091904400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "OPENAI_API_KEY=os.getenv('OPENAI_API_KEY')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:49:03.153902700Z",
     "start_time": "2023-12-22T11:49:03.107903100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 8996.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# loader\n",
    "# use the data from documents to create vector store\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "loader = DirectoryLoader('./data', glob=\"**/*.txt\", loader_cls=TextLoader, show_progress=True)\n",
    "\n",
    "data = loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:50:11.459141100Z",
     "start_time": "2023-12-22T11:50:11.033095700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:18:50.358441700Z",
     "start_time": "2023-12-22T11:18:50.344440100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# chunking the data to store in the database\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:50:12.462380400Z",
     "start_time": "2023-12-22T11:50:12.449380700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:18:52.065417800Z",
     "start_time": "2023-12-22T11:18:52.048404900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niran\\anaconda3\\envs\\pytorch_learning\\lib\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "# embeddings from huggingface\n",
    "# from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "# embeddings = HuggingFaceInstructEmbeddings(model_name='hkunlp/instructor-large')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:50:17.840507400Z",
     "start_time": "2023-12-22T11:50:15.025561800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# embeddings from openai\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:53:11.745896300Z",
     "start_time": "2023-12-22T11:53:11.361138700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# loading vectors into VectorDB\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "vectorstore.save_local(\"vectorstore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:53:13.612821500Z",
     "start_time": "2023-12-22T11:53:12.473266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# load the vectorstore\n",
    "vectorstore = FAISS.load_local(\"vectorstore\", embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:55:08.146419400Z",
     "start_time": "2023-12-22T11:55:08.125660700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T09:58:43.335791500Z",
     "start_time": "2023-12-22T09:58:43.331792Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Prompt to answer question\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"You are a helpful assistant for our restaurant that answers the queries of the customer\n",
    "\n",
    "{context}\n",
    "Question: {question}\n",
    "Answer here: \"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template = prompt_template, input_variables=[\"context\",\"question\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:55:24.904314900Z",
     "start_time": "2023-12-22T11:55:24.875232800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# memory to store chat history\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, output_key=\"answer\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:55:26.715370300Z",
     "start_time": "2023-12-22T11:55:26.711371600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI, HuggingFaceHub\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "chain_type = {\"prompt\": PROMPT}\n",
    "# to use open ai, uncomment it\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# to use models from huggingface, uncomment this\n",
    "# llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":0.5, \"max_length\":512})\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    memory=memory,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    combine_docs_chain_kwargs=chain_type\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:55:27.735093800Z",
     "start_time": "2023-12-22T11:55:27.706094400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "query=\"What are your pricing\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:55:28.552857Z",
     "start_time": "2023-12-22T11:55:28.536857100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "{'question': 'What are your pricing',\n 'chat_history': [HumanMessage(content='What are your pricing'),\n  AIMessage(content='Our pricing varies depending on the menu item. Our starters range from $7-$9, main courses from $16-$26, desserts around $7-$9, and beverages starting at $2. Please refer to our menu for specific item prices.')],\n 'answer': 'Our pricing varies depending on the menu item. Our starters range from $7-$9, main courses from $16-$26, desserts around $7-$9, and beverages starting at $2. Please refer to our menu for specific item prices.'}"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain({\"question\": query})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:55:30.861897Z",
     "start_time": "2023-12-22T11:55:29.079288100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "{'question': 'Why should I come here',\n 'chat_history': [HumanMessage(content='What are your pricing'),\n  AIMessage(content='Our pricing varies depending on the menu item. Our starters range from $7-$9, main courses from $16-$26, desserts around $7-$9, and beverages starting at $2. Please refer to our menu for specific item prices.'),\n  HumanMessage(content='Why should I come here'),\n  AIMessage(content=\" Gourmet Bistro is a great choice for dining because of our delicious and diverse menu, cozy ambiance, and convenient location. We also pride ourselves on exceptional service and have received numerous awards and recognitions for our culinary offerings. Whether you're looking for a casual lunch, a romantic dinner, or a family gathering, Gourmet Bistro has something for everyone.\")],\n 'answer': \" Gourmet Bistro is a great choice for dining because of our delicious and diverse menu, cozy ambiance, and convenient location. We also pride ourselves on exceptional service and have received numerous awards and recognitions for our culinary offerings. Whether you're looking for a casual lunch, a romantic dinner, or a family gathering, Gourmet Bistro has something for everyone.\"}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain({\"question\": \"Why should I come here\"})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:55:37.518651600Z",
     "start_time": "2023-12-22T11:55:35.122389300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
